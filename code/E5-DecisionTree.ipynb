{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree to Diagnose Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to create an intelligent agent, which can suggest a diagnose of heart diseases.<br>\n",
    "The task is to train a model of human heart, based on measurements, taken from numerous heart disease patients.<br>\n",
    "For the training we will use data from a public source: https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas for data structures and operations for manipulating numerical tables and time series\n",
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# matplotlib.pyplot for data plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn for machine learning methods\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for numeric calculations\n",
    "import numpy as np\n",
    "\n",
    "# from utilities import visualize_classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data from file __processed.cleveland.data__ by use of pandas<br>\n",
    "It is a table data in __csv__ format.<br>\n",
    "Columns contain various parameters of human heart. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create URL object\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "# url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/reprocessed.hungarian.data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data has no header, we need to specify the names of each column before loading it. We get the information of interpretation from the file __heart-disease.names__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a header\n",
    "names = ['age','sex','cp','bps','chol','fbs','ecg','hrate','ang','peak','slp','ca','thal','diag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, create a dataset object\n",
    "dataset = pandas.read_csv(url, names=names, na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Get to Know The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Overview\n",
    "Investigate the dataset. <br>\n",
    "Find out how many records are available, are they all clean, how many classes they represent. <br>\n",
    "Create diagrams to visualize the set and its descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the shape (number of rows) and size (number of columns)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how it looks (get the first 5 records)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the descriptive statistics calculated for the whole dataset\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check null values in data\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check null values in data\n",
    "np.isnan(dataset).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data, if needed\n",
    "np.nan_to_num(dataset)\n",
    "dataset[dataset.notnull()]\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by class attribute diag\n",
    "# See how many classes are included and how many records per class are distributed\n",
    "print(dataset.groupby('diag').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Dataset Statistics\n",
    "    1. Draw Box-Whisker Plots\n",
    "    2. Draw Histograms\n",
    "    3. Draw Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw box-whisker plots\n",
    "dataset.plot(kind='box', subplots=True, layout=(3,5), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See explanation of the box-whisker diagram\n",
    "![\"Explanation of box-whisker\"](../images/boxwhisker.gif \"What does it mean?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw histograms for each feature\n",
    "dataset.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These diagrams show the distribution of the values in the columns. <br>\n",
    "Some of them seem to have Normal (Gaussian) distribution.<br> \n",
    "It is good to know, as we can later choose appropriate algorithms for exploitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare The Data For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset into array\n",
    "array = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two (sub) arrays from it\n",
    "# X - features, all rows, all columns but the last one\n",
    "# y - labels, all rows, the last column\n",
    "X, y = array[:, :-1], array[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input data into classes based on labels\n",
    "class0 = np.array(X[y==0])\n",
    "class1 = np.array(X[y==1])\n",
    "class2 = np.array(X[y==2])\n",
    "class3 = np.array(X[y==3])\n",
    "class4 = np.array(X[y==4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training\n",
    "Time to try to train a model.\n",
    "1. Split the dataset into two: __training set__ and __test set__\n",
    "2. Build the classifier by implementing __Decision Tree__ algorithm over the training set\n",
    "3. Test the classifier over the test set\n",
    "3. Estimate how accurate it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into into training and testing sets in proportion 8:2 \n",
    "#   80% of it as training data\n",
    "#   20% as a validation dataset\n",
    "set_prop = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Initialize seed parameter for the random number generator used for the split\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=set_prop, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Decision Trees Classifier \n",
    "params = {'max_depth': 5}\n",
    "classifier = DecisionTreeClassifier(**params)\n",
    "# classifier = RandomForestClassifier(n_estimators = 100, max_depth = 6)\n",
    " \n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize_classifier(classifier, X_train, y_train, 'Training dataset')\n",
    "# visualize_classifier(classifier, X_test, y_test, 'Test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the graphviz package\n",
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw tree from the trained data by graphviz package\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(classifier, out_file=None, \n",
    "                         feature_names=dataset.columns[:13], class_names = True,        \n",
    "                         filled=True, rounded=True, proportion = False,\n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result saved in file heart\n",
    "graph.render(\"heart\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show it here\n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a metrics for the evaluation\n",
    "‘accuracy‘ is the percentage % of correctly predicted instances from the total number of instances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the metrics\n",
    "# scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to implement the model on our test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test data\n",
    "y_testp = classifier.predict(X_test)\n",
    "y_testp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the accuracy of the model comparing the observed data and predicted data\n",
    "print (\"Accuracy is \", accuracy_score(y_test,y_testp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test,y_testp)\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = pandas.crosstab(y_test,y_testp)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "plt.imshow(confusion_mat, interpolation='nearest')\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "ticks = np.arange(5)\n",
    "plt.xticks(ticks, ticks)\n",
    "plt.yticks(ticks, ticks)\n",
    "plt.ylabel('True labels')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(confusion_mat, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The diagonal elements (TN, TP) represent the number of points for which the predicted label is equal to the true label, \n",
    "# while off-diagonal elements are those that are mislabeled by the classifier. \n",
    "# The higher the diagonal values of the confusion matrix the better, indicating many correct predictions.\n",
    "# FN - False Negative prediction\n",
    "# FP - False Positive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix provides an indication of the  errors made in predictions, here in text format\n",
    "# print(confusion_matrix(y_test, y_testp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Class0', 'Class1', 'Class2','Class3', 'Class4']\n",
    "# Classifier performance on training dataset\n",
    "print(classification_report(y_train, classifier.predict(X_train), target_names=class_names))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![\"A measure for comparison of solutions\"](../images/all.jpg \"What does it mean?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"\"](../images/Fmeasure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier performance on test dataset\n",
    "print(classification_report(y_test, classifier.predict(X_test), target_names=class_names))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Task</span>\n",
    "Try to improve the model by applying Random Forest classifier provided in sklearn.<br>\n",
    "Repeat the training, testing and validation.<br>\n",
    "Compare the Decision Tree and Random Forest methods.\n",
    "Answer to the question: Which method gives better results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
